{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38779ff0",
   "metadata": {},
   "source": [
    "# 01 - Data Quality\n",
    "\n",
    "## Objetivo\n",
    "- Ingestar los 3 archivos base del proyecto (microdato, barrios JS, trazabilidad).\n",
    "- Validar columnas reales, nulos, duplicados y outliers.\n",
    "- Normalizar unidades de precio y superficie y registrar reglas en `artifacts/data_dictionary.csv`.\n",
    "- Definir holdout final y guardar evidencias de split.\n",
    "- Guardar un dataset limpio reproducible para EDA y modelado.\n",
    "\n",
    "## Inputs \n",
    "- `/madrid_rent_with_geolocation.csv`\n",
    "- `/alquiler_barrios_madrid_oct2025.js`\n",
    "- `/Como_se_ha_generado_el_dataset_madrid_rent_with_geolocation.csv.txt`\n",
    "\n",
    "## Outputs\n",
    "- `artifacts/data_dictionary.csv`\n",
    "- `artifacts/splits/holdout_ids.csv`\n",
    "- `reports/target_selection.md`\n",
    "- `reports/parse_numeric_report.md`\n",
    "- `reports/environment.txt`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b95032f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T23:44:50.505323Z",
     "iopub.status.busy": "2026-01-21T23:44:50.504471Z",
     "iopub.status.idle": "2026-01-21T23:44:51.294169Z",
     "shell.execute_reply": "2026-01-21T23:44:51.292482Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "import hashlib\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Base setup y reproducibilidad ---\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "def get_repo_root() -> Path:\n",
    "    \"\"\"Return repo root by walking parents and checking .git/pyproject.toml.\"\"\"\n",
    "    current = Path.cwd().resolve()\n",
    "    for parent in [current] + list(current.parents):\n",
    "        if (parent / \".git\").exists() or (parent / \"pyproject.toml\").exists():\n",
    "            return parent\n",
    "    return current\n",
    "\n",
    "# Resolver ROOT y exponerlo al path de imports\n",
    "ROOT = get_repo_root()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6e3fc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T23:44:51.298496Z",
     "iopub.status.busy": "2026-01-21T23:44:51.297990Z",
     "iopub.status.idle": "2026-01-21T23:44:51.435902Z",
     "shell.execute_reply": "2026-01-21T23:44:51.434112Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils import haversine, parse_js_barrios, make_time_splits\n",
    "\n",
    "# --- Crear estructura de carpetas base ---\n",
    "for folder in [\n",
    "    \"artifacts\",\n",
    "    \"artifacts/splits\",\n",
    "    \"models\",\n",
    "    \"reports\",\n",
    "    \"data/external\",\n",
    "    \"data/external/admin\",\n",
    "    \"data/external/socioeco\",\n",
    "    \"data/external/mobility\",\n",
    "    \"data/external/env\",\n",
    "    \"data/external/urban\",\n",
    "    \"data/external/timeseries\",\n",
    "    \"data/external/docs\",\n",
    "]:\n",
    "    (ROOT / folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Rutas de input ---\n",
    "raw_path = ROOT / \"data\" / \"raw\" / \"madrid_rent_with_geolocation.csv\"\n",
    "barrios_js_path = ROOT / \"data\" / \"raw\" / \"alquiler_barrios_madrid_oct2025.js\"\n",
    "trace_path = ROOT / \"data\" / \"raw\" / \"Como_se_ha_generado_el_dataset_madrid_rent_with_geolocation.csv.txt\"\n",
    "\n",
    "# --- Ingesta de datos ---\n",
    "rent_df = pd.read_csv(raw_path)\n",
    "barrios_js_text = barrios_js_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "trace_text = trace_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "# Vista rapida y extracto de trazabilidad\n",
    "print(rent_df.head(3))\n",
    "print(trace_text[:800])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913bc082",
   "metadata": {},
   "source": [
    "**Outputs esperados (tablas)**\n",
    "- Vista rapida de `rent_df` y extracto de trazabilidad.\n",
    "- Tabla con tipos, porcentaje de nulos y ejemplos por columna.\n",
    "- Reportes de parseo numerico y seleccion de target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd05632",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T23:44:51.440023Z",
     "iopub.status.busy": "2026-01-21T23:44:51.439571Z",
     "iopub.status.idle": "2026-01-21T23:44:51.460182Z",
     "shell.execute_reply": "2026-01-21T23:44:51.458458Z"
    }
   },
   "outputs": [],
   "source": [
    "# Resumen de trazabilidad\n",
    "import unicodedata\n",
    "\n",
    "# Tokens a excluir del texto de trazabilidad (ruido de instalaciones, URLs, etc.)\n",
    "skip_tokens = (\n",
    "    \"!pip\",\n",
    "    \"pip \",\n",
    "    \"collecting\",\n",
    "    \"downloading\",\n",
    "    \"requirement\",\n",
    "    \"installing\",\n",
    "    \"whl\",\n",
    "    \"metadata\",\n",
    "    \"http\",\n",
    "    \"kb\",\n",
    "    \"mb\",\n",
    "    \"==\",\n",
    "    \"attempting uninstall\",\n",
    "    \"found existing installation\",\n",
    "    \"successfully uninstalled\",\n",
    "    \"successfully installed\",\n",
    ")\n",
    "clean_lines = []\n",
    "raw_lines = trace_text.splitlines()\n",
    "\n",
    "# Limpieza basica de caracteres invisibles\n",
    "null_char = chr(0)\n",
    "cr_char = chr(13)\n",
    "bom_char = chr(0xFEFF)\n",
    "para_char = chr(0x00B6)\n",
    "newline = chr(10)\n",
    "for line in raw_lines:\n",
    "    line = line.replace(bom_char, \"\").replace(null_char, \"\").replace(cr_char, \"\").replace(para_char, \"\")\n",
    "    low = line.strip().lower()\n",
    "    if any(token in low for token in skip_tokens):\n",
    "        continue\n",
    "    if not low:\n",
    "        continue\n",
    "    if low.startswith(\"import \") or low.startswith(\"#\"):\n",
    "        if clean_lines:\n",
    "            break\n",
    "        continue\n",
    "    # Normalizar a ASCII para evitar mojibake en reportes\n",
    "    line = unicodedata.normalize(\"NFKD\", line).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    clean_lines.append(line)\n",
    "\n",
    "trace_summary = newline.join(clean_lines[:12])\n",
    "text_low = newline.join(raw_lines).lower()\n",
    "context_lines = []\n",
    "if \"kaggle\" in text_low:\n",
    "    context_lines.append(\"- Fuente base referenciada en Kaggle (dataset de alquileres Madrid).\")\n",
    "if \"google maps\" in text_low or \"geolocaliz\" in text_low:\n",
    "    context_lines.append(\"- Geolocalizacion completada con script externo y Google Maps API (segun trazabilidad).\")\n",
    "if \"madrid_rent_geolocation.py\" in text_low:\n",
    "    context_lines.append(\"- Script de geolocalizacion mencionado: madrid_rent_geolocation.py.\")\n",
    "\n",
    "# Bloques narrativos para el reporte de trazabilidad\n",
    "extra = [\n",
    "    \"\",\n",
    "    \"Contexto del origen:\",\n",
    "]\n",
    "if context_lines:\n",
    "    extra.extend(context_lines)\n",
    "else:\n",
    "    extra.append(\"- No se detectaron referencias adicionales en el texto.\")\n",
    "extra += [\n",
    "    \"\",\n",
    "    \"Supuestos y riesgos:\",\n",
    "    \"- Posibles duplicados entre fuentes; se deduplica por id/fingerprint.\",\n",
    "    \"- Temporalidad sin anio; se asume 2025 para ordenar y se documenta la limitacion.\",\n",
    "    \"- Coordenadas/superficie pueden contener errores; se aplican filtros y parseo robusto.\",\n",
    "    \"\",\n",
    "    \"Implicaciones para limpieza/validacion:\",\n",
    "    \"- Filtrado geografico por bbox/radio y percentiles.\",\n",
    "    \"- Preprocesado solo con train via Pipeline/ColumnTransformer.\",\n",
    "]\n",
    "trace_report = ROOT / \"reports\" / \"traceability_summary.md\"\n",
    "trace_report.write_text(\n",
    "    \"## Resumen de trazabilidad\" + newline + newline + trace_summary + newline + newline.join(extra) + newline,\n",
    "    encoding=\"utf-8\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b2d463",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T23:44:51.464299Z",
     "iopub.status.busy": "2026-01-21T23:44:51.463712Z",
     "iopub.status.idle": "2026-01-21T23:44:51.598343Z",
     "shell.execute_reply": "2026-01-21T23:44:51.596138Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tabla de tipos, nulos y ejemplos\n",
    "summary = []\n",
    "for col in rent_df.columns:\n",
    "    series = rent_df[col]\n",
    "    summary.append({\n",
    "        \"column\": col,\n",
    "        \"dtype\": str(series.dtype),\n",
    "        \"null_pct\": round(series.isna().mean() * 100, 2),\n",
    "        \"examples\": series.dropna().astype(str).head(5).tolist(),\n",
    "    })\n",
    "summary_df = pd.DataFrame(summary)\n",
    "summary_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcfe0ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T23:44:51.602353Z",
     "iopub.status.busy": "2026-01-21T23:44:51.601933Z",
     "iopub.status.idle": "2026-01-21T23:44:51.663256Z",
     "shell.execute_reply": "2026-01-21T23:44:51.661512Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalizacion de columnas clave (precio, superficie, precio m2)\n",
    "\n",
    "euro = chr(8364)\n",
    "sup2 = chr(178)\n",
    "\n",
    "# Parser robusto para valores numericos con separadores mixtos\n",
    "\n",
    "def parse_numeric(value):\n",
    "    if value is None or (isinstance(value, float) and np.isnan(value)):\n",
    "        return np.nan\n",
    "    if isinstance(value, (int, float, np.integer, np.floating)):\n",
    "        return float(value)\n",
    "    text = str(value).strip().lower()\n",
    "    if text in {\"\", \"nan\", \"none\", \"null\"}:\n",
    "        return np.nan\n",
    "    text = text.replace(euro, \"\").replace(\"eur\", \"\")\n",
    "    text = text.replace(f\"m{sup2}\", \"m2\").replace(\"m^2\", \"m2\")\n",
    "    text = re.sub(r\"[^0-9,\\.\\-]\", \"\", text)\n",
    "    # Normalizar separadores: 1.234,56 -> 1234.56\n",
    "    if text.count(\",\") and text.count(\".\"):\n",
    "        text = text.replace(\".\", \"\")\n",
    "        text = text.replace(\",\", \".\")\n",
    "    elif text.count(\",\") and not text.count(\".\"):\n",
    "        text = text.replace(\",\", \".\")\n",
    "    try:\n",
    "        return float(text)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def pick_first(candidates, preferred=None):\n",
    "    # Selecciona una columna candidata priorizando un nombre conocido\n",
    "    if preferred and preferred in candidates:\n",
    "        return preferred\n",
    "    return candidates[0] if candidates else None\n",
    "\n",
    "\n",
    "def _parse_with_report(series: pd.Series, col_name: str, standard: str):\n",
    "    # Aplica parseo y mide perdida de informacion\n",
    "    parsed = series.apply(parse_numeric)\n",
    "    raw_non_null = series.notna().sum()\n",
    "    parsed_non_null = parsed.notna().sum()\n",
    "    loss_pct = 0.0 if raw_non_null == 0 else round((raw_non_null - parsed_non_null) / raw_non_null * 100, 2)\n",
    "    fallback_used = False\n",
    "    # Fallback si el parseo pierde demasiado (>30%)\n",
    "    if raw_non_null > 0 and loss_pct > 30:\n",
    "        extracted = series.astype(str).str.extract(r\"(-?[0-9]+(?:[\\.,][0-9]+)?)\")[0]\n",
    "        extracted = extracted.str.replace(\",\", \".\", regex=False)\n",
    "        fallback = pd.to_numeric(extracted, errors=\"coerce\")\n",
    "        fallback_non_null = fallback.notna().sum()\n",
    "        fallback_loss_pct = 0.0 if raw_non_null == 0 else round((raw_non_null - fallback_non_null) / raw_non_null * 100, 2)\n",
    "        if fallback_loss_pct < loss_pct:\n",
    "            parsed = fallback\n",
    "            loss_pct = fallback_loss_pct\n",
    "            fallback_used = True\n",
    "    parse_report.append({\n",
    "        \"column\": col_name,\n",
    "        \"standard\": standard,\n",
    "        \"loss_pct\": loss_pct,\n",
    "        \"fallback_used\": fallback_used,\n",
    "        \"raw_non_null\": int(raw_non_null),\n",
    "    })\n",
    "    return parsed\n",
    "\n",
    "# Detectar columnas candidatas por nombre\n",
    "lower_cols = {col: col.lower() for col in rent_df.columns}\n",
    "price_candidates = [col for col, low in lower_cols.items() if re.search(r\"price|precio\", low) and not re.search(r\"m2|m\\^2\", low)]\n",
    "price_m2_candidates = [col for col, low in lower_cols.items() if re.search(r\"price|precio\", low) and re.search(r\"m2|m\\^2\", low)]\n",
    "surface_candidates = [\n",
    "    col for col, low in lower_cols.items()\n",
    "    if re.search(r\"surface|superficie|area|m2|metros\", low)\n",
    "    and not re.search(r\"price|precio\", low)\n",
    "]\n",
    "\n",
    "price_col = pick_first(price_candidates, preferred=\"price\")\n",
    "price_m2_col = pick_first(price_m2_candidates)\n",
    "surface_col = pick_first(surface_candidates, preferred=\"floor_area\")\n",
    "\n",
    "rules = []\n",
    "parse_report = []\n",
    "if price_col:\n",
    "    rent_df[\"price\"] = _parse_with_report(rent_df[price_col], price_col, \"price\")\n",
    "    rules.append({\"column\": price_col, \"standard\": \"price\", \"rule\": \"parsed_numeric_eur_month\"})\n",
    "if surface_col:\n",
    "    rent_df[\"surface_m2\"] = _parse_with_report(rent_df[surface_col], surface_col, \"surface_m2\")\n",
    "    rules.append({\"column\": surface_col, \"standard\": \"surface_m2\", \"rule\": \"parsed_numeric_m2\"})\n",
    "if price_m2_col:\n",
    "    rent_df[\"price_m2\"] = _parse_with_report(rent_df[price_m2_col], price_m2_col, \"price_m2\")\n",
    "    rules.append({\"column\": price_m2_col, \"standard\": \"price_m2\", \"rule\": \"parsed_numeric_eur_m2\"})\n",
    "\n",
    "# Derivar price_m2 si no existe pero hay price y surface\n",
    "if \"price_m2\" not in rent_df.columns and \"price\" in rent_df.columns and \"surface_m2\" in rent_df.columns:\n",
    "    rent_df[\"price_m2\"] = rent_df[\"price\"] / rent_df[\"surface_m2\"].replace({0: np.nan})\n",
    "    rules.append({\"column\": \"derived\", \"standard\": \"price_m2\", \"rule\": \"price / surface_m2\"})\n",
    "\n",
    "# Guardar diccionario de datos y reporte de parseo\n",
    "pd.DataFrame(rules).to_csv(ROOT / \"artifacts\" / \"data_dictionary.csv\", index=False)\n",
    "\n",
    "report_lines = [\"## Perdida de informacion tras parseo\", \"\"]\n",
    "for row in parse_report:\n",
    "    report_lines.append(f\"- {row['column']}: {row['loss_pct']}% (fallback={row['fallback_used']})\")\n",
    "report_lines.append(\"\")\n",
    "report_lines.append(\"## Fallback aplicado\")\n",
    "for row in parse_report:\n",
    "    if row[\"fallback_used\"]:\n",
    "        report_lines.append(f\"- {row['column']}: fallback mejoro la perdida\")\n",
    "if not any(row[\"fallback_used\"] for row in parse_report):\n",
    "    report_lines.append(\"- Ninguno\")\n",
    "\n",
    "(ROOT / \"reports\" / \"parse_numeric_report.md\").write_text(\"\".join(report_lines), encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da6c0e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T23:44:51.666859Z",
     "iopub.status.busy": "2026-01-21T23:44:51.666418Z",
     "iopub.status.idle": "2026-01-21T23:44:51.703948Z",
     "shell.execute_reply": "2026-01-21T23:44:51.701939Z"
    }
   },
   "outputs": [],
   "source": [
    "# Seleccion de target (price / price_m2) y evidencia\n",
    "\n",
    "derived_price_m2 = price_m2_col is None and \"price\" in rent_df.columns and \"surface_m2\" in rent_df.columns\n",
    "price_m2_source = price_m2_col or (\"derived_from_price_surface\" if derived_price_m2 else None)\n",
    "\n",
    "euro = chr(8364)\n",
    "sup2 = chr(178)\n",
    "\n",
    "selection_report = ROOT / \"reports\" / \"target_selection.md\"\n",
    "with selection_report.open(\"w\", encoding=\"utf-8\") as handle:\n",
    "    handle.write(\"# Seleccion de target\\n\\n\")\n",
    "    handle.write(f\"- Columna precio mensual candidata: {price_col}\\n\")\n",
    "    handle.write(f\"- Columna superficie candidata: {surface_col}\\n\")\n",
    "    handle.write(f\"- Columna precio m2 candidata: {price_m2_source}\\n\\n\")\n",
    "    if price_col is None:\n",
    "        handle.write(\"- No se encontro una columna clara de precio mensual.\\n\")\n",
    "    if surface_col is None:\n",
    "        handle.write(\"- No se encontro una columna clara de superficie.\\n\")\n",
    "    if price_m2_col is None:\n",
    "        if derived_price_m2:\n",
    "            handle.write(\"- Se derivo price_m2 desde precio mensual y superficie.\\n\")\n",
    "        else:\n",
    "            handle.write(\"- No se encontro una columna clara de precio por m2.\\n\")\n",
    "\n",
    "    if price_col:\n",
    "        raw_price = rent_df[price_col].astype(str).str.lower()\n",
    "        raw_norm = raw_price.str.replace(euro, \"\", regex=False).str.replace(sup2, \"2\", regex=False)\n",
    "        mixed_m2 = raw_norm.str.contains(\"m2\") | raw_norm.str.contains(\"m^2\")\n",
    "        mixed_count = int(mixed_m2.sum())\n",
    "        if mixed_count > 0:\n",
    "            handle.write(f\"- Aviso: {mixed_count} filas en {price_col} contienen indicios de m2.\\n\")\n",
    "        else:\n",
    "            handle.write(\"- No se detectaron strings tipo m2 en la columna de precio.\\n\")\n",
    "\n",
    "        stats = rent_df[\"price\"].describe(percentiles=[0.1, 0.5, 0.9]).to_dict()\n",
    "        handle.write(\"\\n## Estadisticas rapidas price\\n\")\n",
    "        for key, value in stats.items():\n",
    "            handle.write(f\"- {key}: {value}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e55987c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T23:44:51.707672Z",
     "iopub.status.busy": "2026-01-21T23:44:51.707133Z",
     "iopub.status.idle": "2026-01-21T23:44:51.724241Z",
     "shell.execute_reply": "2026-01-21T23:44:51.722436Z"
    }
   },
   "outputs": [],
   "source": [
    "# Duplicados defendibles\n",
    "if \"id\" in rent_df.columns:\n",
    "    dedup_key = \"id\"\n",
    "elif \"url\" in rent_df.columns:\n",
    "    dedup_key = \"url\"\n",
    "else:\n",
    "    # Construir fingerprint con columnas numericas y categoricas cortas\n",
    "    lat_col = next((c for c in rent_df.columns if \"lat\" in c.lower()), None)\n",
    "    lon_col = next((c for c in rent_df.columns if \"lon\" in c.lower() or \"lng\" in c.lower()), None)\n",
    "    numeric_cols = [\n",
    "        c for c in rent_df.columns\n",
    "        if c not in [\"price\", \"price_m2\"] and pd.api.types.is_numeric_dtype(rent_df[c])\n",
    "    ]\n",
    "    obj_cols = [c for c in rent_df.columns if rent_df[c].dtype == \"object\"]\n",
    "    short_obj_cols = []\n",
    "    for col in obj_cols:\n",
    "        sample = rent_df[col].dropna().astype(str)\n",
    "        if sample.empty:\n",
    "            continue\n",
    "        avg_len = sample.str.len().mean()\n",
    "        unique_ratio = sample.nunique() / len(sample)\n",
    "        if avg_len <= 50 and unique_ratio <= 0.8:\n",
    "            short_obj_cols.append(col)\n",
    "    core_cols = numeric_cols + short_obj_cols\n",
    "    temp_df = rent_df[core_cols].copy() if core_cols else rent_df.copy()\n",
    "    if lat_col and lon_col:\n",
    "        temp_df[lat_col] = rent_df[lat_col].round(5)\n",
    "        temp_df[lon_col] = rent_df[lon_col].round(5)\n",
    "    hash_source = temp_df.fillna(\"NA\").astype(str).agg(\"|\".join, axis=1)\n",
    "    rent_df[\"listing_fingerprint\"] = hash_source.apply(lambda x: hashlib.md5(x.encode()).hexdigest())\n",
    "    dedup_key = \"listing_fingerprint\"\n",
    "\n",
    "before = len(rent_df)\n",
    "rent_df = rent_df.drop_duplicates(subset=[dedup_key])\n",
    "after = len(rent_df)\n",
    "print(f\"Duplicados removidos: {before - after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed4fd6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T23:44:51.728835Z",
     "iopub.status.busy": "2026-01-21T23:44:51.728111Z",
     "iopub.status.idle": "2026-01-21T23:44:51.877770Z",
     "shell.execute_reply": "2026-01-21T23:44:51.876129Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filtrado geografico: bbox + distancia al centro\n",
    "center_lat, center_lon = 40.4168, -3.7038\n",
    "lat_col = next((c for c in rent_df.columns if \"lat\" in c.lower()), None)\n",
    "lon_col = next((c for c in rent_df.columns if \"lon\" in c.lower() or \"lng\" in c.lower()), None)\n",
    "\n",
    "if lat_col and lon_col:\n",
    "    # Distancia al centro y recorte por percentil alto\n",
    "    rent_df[\"distance_center_km\"] = rent_df.apply(\n",
    "        lambda row: haversine(center_lat, center_lon, row[lat_col], row[lon_col]), axis=1\n",
    "    )\n",
    "    max_km = min(30, rent_df[\"distance_center_km\"].quantile(0.995))\n",
    "    rent_df = rent_df[rent_df[\"distance_center_km\"] <= max_km]\n",
    "\n",
    "    # Filtro bbox robusto (0.5%-99.5%)\n",
    "    lat_low, lat_high = rent_df[lat_col].quantile([0.005, 0.995])\n",
    "    lon_low, lon_high = rent_df[lon_col].quantile([0.005, 0.995])\n",
    "    rent_df = rent_df[(rent_df[lat_col].between(lat_low, lat_high)) & (rent_df[lon_col].between(lon_low, lon_high))]\n",
    "\n",
    "# Reindex tras filtros para alinear indices con el holdout\n",
    "rent_df = rent_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a027218",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T23:44:51.882097Z",
     "iopub.status.busy": "2026-01-21T23:44:51.881651Z",
     "iopub.status.idle": "2026-01-21T23:44:51.895524Z",
     "shell.execute_reply": "2026-01-21T23:44:51.893599Z"
    }
   },
   "outputs": [],
   "source": [
    "# Outliers basicos (IQR) para price y surface_m2\n",
    "outlier_report = {}\n",
    "for col in [\"price\", \"surface_m2\"]:\n",
    "    if col in rent_df.columns:\n",
    "        q1, q3 = rent_df[col].quantile([0.25, 0.75])\n",
    "        iqr = q3 - q1\n",
    "        lower, upper = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "        outlier_pct = ((rent_df[col] < lower) | (rent_df[col] > upper)).mean() * 100\n",
    "        outlier_report[col] = round(outlier_pct, 2)\n",
    "\n",
    "outlier_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bb4397",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T23:44:51.899355Z",
     "iopub.status.busy": "2026-01-21T23:44:51.898774Z",
     "iopub.status.idle": "2026-01-21T23:44:54.180567Z",
     "shell.execute_reply": "2026-01-21T23:44:54.178574Z"
    }
   },
   "outputs": [],
   "source": [
    "# Holdout final fijo (temporal si hay fecha fiable)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "HOLDOUT_TEST_SIZE = 0.2\n",
    "GAP_DAYS = 7\n",
    "\n",
    "# Detectar columna temporal\n",
    "\n",
    "date_keys = (\"date\", \"fecha\", \"update\", \"scrape\", \"publica\")\n",
    "date_cols = [c for c in rent_df.columns if any(k in c.lower() for k in date_keys)]\n",
    "temporal_ok = False\n",
    "date_col = None\n",
    "assumed_year = None\n",
    "if date_cols:\n",
    "    date_col = date_cols[0]\n",
    "    date_series = rent_df[date_col].dropna().astype(str).str.strip()\n",
    "    if not date_series.empty:\n",
    "        has_year = date_series.str.contains(r\"\\d{4}\")\n",
    "        day_month_only = date_series.str.match(r\"^\\d{1,2}\\s+[A-Za-z]+$\")\n",
    "        if day_month_only.all() and not has_year.any():\n",
    "            assumed_year = 2025\n",
    "            parsed = pd.to_datetime(\n",
    "                date_series + f\" {assumed_year}\",\n",
    "                errors=\"coerce\",\n",
    "                format=\"%d %B %Y\",\n",
    "            )\n",
    "            if parsed.notna().sum() == 0:\n",
    "                temporal_ok = False\n",
    "                (ROOT / \"reports\" / \"temporal_limitations.md\").write_text(\n",
    "                    f\"La columna {date_col} no incluye anio y no se pudo parsear con anio asumido.\",\n",
    "                    encoding=\"utf-8\",\n",
    "                )\n",
    "            else:\n",
    "                temporal_ok = True\n",
    "                rent_df.loc[parsed.index, date_col] = parsed\n",
    "                (ROOT / \"reports\" / \"temporal_limitations.md\").write_text(\n",
    "                    f\"La columna {date_col} solo trae dia/mes; se asume anio {assumed_year} para ordenar temporalmente.\",\n",
    "                    encoding=\"utf-8\",\n",
    "                )\n",
    "        else:\n",
    "            temporal_ok = True\n",
    "            rent_df[date_col] = pd.to_datetime(rent_df[date_col], errors=\"coerce\", format=\"mixed\")\n",
    "else:\n",
    "    (ROOT / \"reports\" / \"temporal_limitations.md\").write_text(\n",
    "        \"No se detectaron columnas temporales fiables para holdout temporal.\",\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "\n",
    "# Split holdout (temporal o aleatorio)\n",
    "if temporal_ok:\n",
    "    train_idx, test_idx = make_time_splits(\n",
    "        rent_df,\n",
    "        date_col,\n",
    "        test_size=HOLDOUT_TEST_SIZE,\n",
    "        seed=SEED,\n",
    "        gap_days=GAP_DAYS,\n",
    "    )\n",
    "else:\n",
    "    train_idx, test_idx = train_test_split(rent_df.index, test_size=HOLDOUT_TEST_SIZE, random_state=SEED)\n",
    "\n",
    "# Guardar indices de split\n",
    "np.savez(ROOT / \"artifacts\" / \"splits\" / \"holdout_indices.npz\", train_idx=train_idx, test_idx=test_idx)\n",
    "\n",
    "split_config = {\n",
    "    \"date_col\": date_col,\n",
    "    \"temporal_ok\": bool(temporal_ok),\n",
    "    \"test_size\": HOLDOUT_TEST_SIZE,\n",
    "    \"gap_days\": GAP_DAYS if temporal_ok else 0,\n",
    "    \"assumed_year\": assumed_year,\n",
    "}\n",
    "(ROOT / \"artifacts\" / \"splits\" / \"split_config.json\").write_text(\n",
    "    json.dumps(split_config, ensure_ascii=False, indent=2),\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "\n",
    "# Guardar ids/fingerprint por split\n",
    "id_col = None\n",
    "if \"id\" in rent_df.columns:\n",
    "    id_col = \"id\"\n",
    "elif \"url\" in rent_df.columns:\n",
    "    id_col = \"url\"\n",
    "elif \"listing_fingerprint\" in rent_df.columns:\n",
    "    id_col = \"listing_fingerprint\"\n",
    "\n",
    "if id_col:\n",
    "    split_labels = pd.Series(\"train\", index=rent_df.index)\n",
    "    split_labels.loc[test_idx] = \"holdout\"\n",
    "    holdout_ids = rent_df.loc[:, [id_col]].copy()\n",
    "    holdout_ids[\"split\"] = split_labels.values\n",
    "    holdout_ids.to_csv(ROOT / \"artifacts\" / \"splits\" / \"holdout_ids.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e87a16c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T23:44:54.184447Z",
     "iopub.status.busy": "2026-01-21T23:44:54.183968Z",
     "iopub.status.idle": "2026-01-21T23:44:54.488884Z",
     "shell.execute_reply": "2026-01-21T23:44:54.487287Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parsear barriosMadrid y guardar artefacto\n",
    "barrios = parse_js_barrios(barrios_js_text)\n",
    "if barrios:\n",
    "    with (ROOT / \"artifacts\" / \"barriosMadrid.json\").open(\"w\", encoding=\"utf-8\") as handle:\n",
    "        json.dump(barrios, handle, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c08399",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T23:44:54.492679Z",
     "iopub.status.busy": "2026-01-21T23:44:54.492265Z",
     "iopub.status.idle": "2026-01-21T23:44:56.166809Z",
     "shell.execute_reply": "2026-01-21T23:44:56.165370Z"
    }
   },
   "outputs": [],
   "source": [
    "# Guardar artefacto procesado\n",
    "out_path = ROOT / \"artifacts\" / \"processed_rent.parquet\"\n",
    "try:\n",
    "    rent_df.to_parquet(out_path, index=False)\n",
    "except Exception:\n",
    "    out_path = ROOT / \"artifacts\" / \"processed_rent.csv.gz\"\n",
    "    rent_df.to_csv(out_path, index=False, compression=\"gzip\")\n",
    "\n",
    "# Registrar entorno (python -V y pip freeze)\n",
    "import subprocess\n",
    "py_version = subprocess.check_output([\"python\", \"-V\"]).decode().strip()\n",
    "reqs = subprocess.check_output([\"python\", \"-m\", \"pip\", \"freeze\"]).decode().strip()\n",
    "with (ROOT / \"reports\" / \"environment.txt\").open(\"w\", encoding=\"utf-8\") as handle:\n",
    "    handle.write(py_version + \"\" + reqs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274919ec",
   "metadata": {},
   "source": [
    "**Outputs esperados (figuras)**\n",
    "- Histogramas de price, price_m2, surface_m2 y distancia al centro.\n",
    "- Barras de missingness por columna.\n",
    "- Dispersion geoespacial (lon/lat) para detectar outliers.\n",
    "- Scatter price vs surface_m2 para validar coherencia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54550bdf",
   "metadata": {},
   "source": [
    "### Visualizaciones de calidad\n",
    "- Revisar colas extremas (precios/superficies) y clusters fuera de Madrid.\n",
    "- Confirmar que la distribucion de lat/lon cae dentro de la bbox esperada.\n",
    "- Validar la relacion price vs surface_m2 (tendencia positiva).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab0dee5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T23:44:56.170682Z",
     "iopub.status.busy": "2026-01-21T23:44:56.170072Z",
     "iopub.status.idle": "2026-01-21T23:44:58.627053Z",
     "shell.execute_reply": "2026-01-21T23:44:58.625066Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Distribuciones basicas de numericas clave\n",
    "numeric_cols = [c for c in [\"price\", \"price_m2\", \"surface_m2\", \"distance_center_km\"] if c in rent_df.columns]\n",
    "if numeric_cols:\n",
    "    plot_df = rent_df[numeric_cols].replace([np.inf, -np.inf], np.nan)\n",
    "    plot_df.hist(figsize=(12, 6), bins=40)\n",
    "    plt.suptitle(\"Distribuciones principales\")\n",
    "    plt.show()\n",
    "\n",
    "# Top columnas con mayor missingness\n",
    "missing = rent_df.isna().mean().sort_values(ascending=False).head(20)\n",
    "plt.figure(figsize=(6, 4))\n",
    "missing.plot(kind=\"barh\")\n",
    "plt.title(\"Top 20 columnas con nulos\")\n",
    "plt.xlabel(\"% nulos\")\n",
    "plt.show()\n",
    "\n",
    "# Dispersion geografica\n",
    "if lat_col and lon_col:\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(rent_df[lon_col], rent_df[lat_col], s=4, alpha=0.4)\n",
    "    plt.title(\"Distribucion geografica de anuncios\")\n",
    "    plt.xlabel(\"Lon\")\n",
    "    plt.ylabel(\"Lat\")\n",
    "    plt.show()\n",
    "\n",
    "# Relacion precio vs superficie\n",
    "if \"price\" in rent_df.columns and \"surface_m2\" in rent_df.columns and len(rent_df) > 0:\n",
    "    sample = rent_df.sample(min(2000, len(rent_df)), random_state=SEED)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.scatterplot(data=sample, x=\"surface_m2\", y=\"price\", alpha=0.4)\n",
    "    plt.title(\"Precio vs superficie\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60231fca",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "**Hallazgos**\n",
    "- Completar con resultados de esta ejecucion.\n",
    "\n",
    "**Decisiones**\n",
    "- Completar con reglas aplicadas (parseo, deduplicacion, filtros).\n",
    "\n",
    "**Siguientes pasos**\n",
    "- Continuar con `02_eda.ipynb` usando `artifacts/processed_rent.*`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
